#!/bin/bash
# =============================================================================
# bs - Benchmark Script (Atomic, Composable Commands)
# =============================================================================
# Philosophy: Do one thing well. Compose small tasks into larger workflows.
#
# Example workflow:
#   ./bs tf apply && ./bs wait && ./bs sync
#   ./bs run primary config repl
#   ./bs run sync replica & ./bs run async replica & wait
#   ./bs run proxy config
#   ./bs verify
#   ./bs bench 11 && ./bs results
# =============================================================================

set -eo pipefail

# =============================================================================
# GLOBALS
# =============================================================================

SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
INFRA_JSON="$SCRIPT_DIR/infra.json"
TERRAFORM_DIR="$SCRIPT_DIR/terraform/topologies/proxy-primary"
LOCAL_RESULTS="$SCRIPT_DIR/results"
REMOTE_HOME="/home/ubuntu"

# Flags (set by parse_flags)
DRY_RUN=false
VERBOSE=false
NO_COLOR=false

# Exit codes
EXIT_OK=0
EXIT_ERROR=1
EXIT_ARGS=2
EXIT_SSH=3
EXIT_REMOTE=4
EXIT_NO_INFRA=5

# SSH options
SSH_OPTS="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=QUIET -o BatchMode=yes"

# Colors (disabled if NO_COLOR)
setup_colors() {
    if [[ "$NO_COLOR" == "true" ]] || [[ ! -t 1 ]]; then
        RED="" GREEN="" YELLOW="" BLUE="" CYAN="" NC=""
    else
        RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[1;33m'
        BLUE='\033[0;34m' CYAN='\033[0;36m' NC='\033[0m'
    fi
}

# =============================================================================
# LOGGING
# =============================================================================

log()   { echo -e "${GREEN}[bs]${NC} $1"; }
info()  { echo -e "${CYAN}[bs]${NC} $1"; }
warn()  { echo -e "${YELLOW}[bs]${NC} $1"; }
error() { echo -e "${RED}[bs]${NC} $1" >&2; }
die()   { error "$1"; exit "${2:-$EXIT_ERROR}"; }

debug() {
    [[ "$VERBOSE" == "true" ]] && echo -e "${BLUE}[cmd]${NC} $1"
    return 0
}

dry() {
    if [[ "$DRY_RUN" == "true" ]]; then
        echo -e "${YELLOW}[dry-run]${NC} $1"
        return 0
    fi
    return 1
}

# =============================================================================
# FLAG PARSING
# =============================================================================

# Parse flags and set REMAINING_ARGS array
parse_flags() {
    REMAINING_ARGS=()
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -n|--dry-run)  DRY_RUN=true; shift ;;
            -v|--verbose)  VERBOSE=true; shift ;;
            --no-color)    NO_COLOR=true; shift ;;
            -*)            die "Unknown flag: $1" $EXIT_ARGS ;;
            *)             REMAINING_ARGS+=("$1"); shift ;;
        esac
    done
    setup_colors
}

# =============================================================================
# NODE HELPERS
# =============================================================================

require_infra() {
    if [[ "$DRY_RUN" == "true" ]]; then
        [[ ! -f "$INFRA_JSON" ]] && warn "infra.json missing (dry-run continues)"
        return 0
    fi
    [[ -f "$INFRA_JSON" ]] || die "No infra.json. Run: ./bs tf apply" $EXIT_NO_INFRA
}

get_ip() {
    local node=$1 field=${2:-public_ip}
    require_infra

    # Return placeholder in dry-run without infra.json
    if [[ "$DRY_RUN" == "true" ]] && [[ ! -f "$INFRA_JSON" ]]; then
        echo "<${node}-${field}>"
        return 0
    fi

    case "$node" in
        primary)      jq -r ".db_nodes.value.primary.$field" "$INFRA_JSON" ;;
        sync)         jq -r ".db_nodes.value.sync_replica.$field" "$INFRA_JSON" ;;
        async)        jq -r ".db_nodes.value.async_replica.$field" "$INFRA_JSON" ;;
        proxy)        jq -r ".proxy_node.value.$field" "$INFRA_JSON" ;;
        *)            die "Unknown node: $node" $EXIT_ARGS ;;
    esac
}

all_nodes() { echo "primary sync async proxy"; }

db_nodes() { echo "primary sync async"; }

validate_node() {
    local node=$1
    case "$node" in
        primary|sync|async|proxy|all) return 0 ;;
        *) die "Invalid node: $node (use: primary|sync|async|proxy|all)" $EXIT_ARGS ;;
    esac
}

# =============================================================================
# SSH HELPERS
# =============================================================================

ssh_exec() {
    local node=$1; shift
    local ip=$(get_ip "$node")
    local cmd="$*"

    debug "ssh ubuntu@$ip \"$cmd\""

    if dry "ssh ubuntu@$ip \"$cmd\""; then
        return 0
    fi

    ssh $SSH_OPTS "ubuntu@$ip" "$cmd"
    local rc=$?

    [[ "$VERBOSE" == "true" ]] && echo -e "${BLUE}[exit]${NC} $rc"
    return $rc
}

ssh_check() {
    local ip=$1
    ssh $SSH_OPTS "ubuntu@$ip" "echo ok" &>/dev/null
}

rsync_to() {
    local node=$1
    local ip=$(get_ip "$node")

    debug "rsync scripts/ -> $node ($ip)"

    if dry "rsync -avz scripts/ ubuntu@$ip:$REMOTE_HOME/scripts/"; then
        return 0
    fi

    ssh $SSH_OPTS "ubuntu@$ip" "sudo chown -R ubuntu:ubuntu $REMOTE_HOME/scripts 2>/dev/null || mkdir -p $REMOTE_HOME/scripts"
    rsync -avz --delete -e "ssh $SSH_OPTS" "$SCRIPT_DIR/scripts/" "ubuntu@$ip:$REMOTE_HOME/scripts/"
}

rsync_from() {
    local node=$1
    local ip=$(get_ip "$node")

    debug "rsync results <- $node ($ip)"

    if dry "rsync ubuntu@$ip:$REMOTE_HOME/scripts/results/ $LOCAL_RESULTS/"; then
        return 0
    fi

    mkdir -p "$LOCAL_RESULTS"
    rsync -avz -e "ssh $SSH_OPTS" "ubuntu@$ip:$REMOTE_HOME/scripts/results/" "$LOCAL_RESULTS/" 2>/dev/null || true
}

# =============================================================================
# SCRIPT MAPPING
# =============================================================================

# Map short names to actual scripts (bash 3.2 compatible)
get_script_file() {
    local name=$1
    case "$name" in
        deps)          echo "00-deps.sh" ;;
        os)            echo "01-os-tuning.sh" ;;
        raid)          echo "02-raid-setup.sh" ;;
        disk)          echo "03-disk-tuning.sh" ;;
        pg)            echo "04-postgres.sh" ;;
        repl)          echo "04b-replication.sh" ;;
        pgcat)         echo "06-pgcat.sh" ;;
        pgbench-init)  echo "05-pgbench-init.sh" ;;
        sysbench-init) echo "07-sysbench-init.sh" ;;
        *)             echo "" ;;
    esac
}

VALID_SCRIPTS="deps os raid disk pg repl pgcat pgbench-init sysbench-init"

# Script groups
expand_group() {
    local group=$1
    case "$group" in
        config)  echo "deps os raid disk pg" ;;
        replica) echo "deps os raid disk pg repl" ;;
        all)     echo "deps os raid disk pg repl pgbench-init sysbench-init" ;;
        *)       echo "$group" ;;  # Not a group, return as-is
    esac
}

get_script_path() {
    local name=$1
    local script=$(get_script_file "$name")
    [[ -z "$script" ]] && die "Unknown script: $name\nValid: $VALID_SCRIPTS | config replica all" $EXIT_ARGS
    echo "$REMOTE_HOME/scripts/setup/$script"
}

get_role_env() {
    local node=$1
    case "$node" in
        primary) echo "ROLE=primary" ;;
        sync)    echo "ROLE=sync-replica" ;;
        async)   echo "ROLE=async-replica" ;;
        proxy)   echo "" ;;
    esac
}

# =============================================================================
# COMMANDS: TERRAFORM
# =============================================================================

cmd_tf() {
    local subcmd=${1:-}

    case "$subcmd" in
        apply)
            log "Terraform apply..."
            if dry "cd $TERRAFORM_DIR && terraform apply -auto-approve"; then
                return 0
            fi
            cd "$TERRAFORM_DIR"
            terraform apply -auto-approve
            terraform output -json > "$INFRA_JSON"
            cd "$SCRIPT_DIR"
            log "infra.json generated"
            ;;
        destroy)
            log "Terraform destroy..."
            if dry "cd $TERRAFORM_DIR && terraform destroy -auto-approve"; then
                return 0
            fi
            cd "$TERRAFORM_DIR"
            terraform destroy -auto-approve
            rm -f "$INFRA_JSON"
            cd "$SCRIPT_DIR"
            log "Infrastructure destroyed"
            ;;
        output)
            log "Regenerating infra.json..."
            if dry "terraform output -json > infra.json"; then
                return 0
            fi
            cd "$TERRAFORM_DIR"
            terraform output -json > "$INFRA_JSON"
            cd "$SCRIPT_DIR"
            log "infra.json regenerated"
            ;;
        *)
            die "Usage: ./bs tf <apply|destroy|output>" $EXIT_ARGS
            ;;
    esac
}

# =============================================================================
# COMMANDS: CONNECTIVITY
# =============================================================================

cmd_test() {
    log "Testing infrastructure..."

    # Check infra.json
    if [[ -f "$INFRA_JSON" ]]; then
        echo -e "  ${GREEN}✓${NC} infra.json exists"
    else
        echo -e "  ${RED}✗${NC} infra.json missing"
        return $EXIT_NO_INFRA
    fi

    # Check SSH to each node
    local failed=0
    for node in $(all_nodes); do
        local ip=$(get_ip "$node" 2>/dev/null || echo "")
        if [[ -z "$ip" ]] || [[ "$ip" == "null" ]]; then
            echo -e "  ${RED}✗${NC} $node: no IP in infra.json"
            ((failed++))
            continue
        fi

        if ssh_check "$ip"; then
            echo -e "  ${GREEN}✓${NC} $node: $ip (SSH OK)"
        else
            echo -e "  ${RED}✗${NC} $node: $ip (SSH FAILED)"
            ((failed++))
        fi
    done

    # Check scripts synced (compare hash)
    for node in $(all_nodes); do
        local ip=$(get_ip "$node" 2>/dev/null || echo "")
        [[ -z "$ip" ]] || [[ "$ip" == "null" ]] && continue

        local remote_exists=$(ssh $SSH_OPTS "ubuntu@$ip" "test -d $REMOTE_HOME/scripts && echo yes || echo no" 2>/dev/null)
        if [[ "$remote_exists" == "yes" ]]; then
            echo -e "  ${GREEN}✓${NC} $node: scripts synced"
        else
            echo -e "  ${YELLOW}!${NC} $node: scripts not synced"
        fi
    done

    [[ $failed -eq 0 ]] && log "All tests passed" || warn "$failed node(s) failed"
    return $failed
}

cmd_wait() {
    local node=${1:-all}
    validate_node "$node"

    local nodes
    [[ "$node" == "all" ]] && nodes=$(all_nodes) || nodes="$node"

    for n in $nodes; do
        local ip=$(get_ip "$n")
        log "Waiting for SSH on $n ($ip)..."

        if dry "wait for SSH on $ip"; then
            continue
        fi

        local i
        for i in {1..60}; do
            if ssh_check "$ip"; then
                log "$n: SSH ready"
                break
            fi
            echo -n "."
            sleep 5
        done

        if ! ssh_check "$ip"; then
            die "$n: SSH timeout" $EXIT_SSH
        fi
    done
}

cmd_sync() {
    local node=${1:-all}
    validate_node "$node"

    local nodes
    [[ "$node" == "all" ]] && nodes=$(all_nodes) || nodes="$node"

    for n in $nodes; do
        log "Syncing scripts to $n..."
        rsync_to "$n"
    done
}

cmd_ssh() {
    local node=${1:-primary}
    validate_node "$node"
    [[ "$node" == "all" ]] && die "Cannot SSH to 'all'. Specify a node." $EXIT_ARGS

    local ip=$(get_ip "$node")
    log "SSH to $node ($ip)..."

    if dry "ssh ubuntu@$ip"; then
        return 0
    fi

    ssh $SSH_OPTS "ubuntu@$ip"
}

# =============================================================================
# COMMANDS: RUN
# =============================================================================

cmd_run() {
    local node=${1:-}
    shift || true
    local scripts=("$@")

    [[ -z "$node" ]] && die "Usage: ./bs run <node> <scripts...>\n  node: primary|sync|async|proxy\n  scripts: deps os raid disk pg repl pgcat pgbench-init sysbench-init\n  groups: config replica all" $EXIT_ARGS
    [[ ${#scripts[@]} -eq 0 ]] && die "No scripts specified.\nValid: ${!SCRIPT_MAP[*]} | config replica all" $EXIT_ARGS

    validate_node "$node"
    [[ "$node" == "all" ]] && die "Cannot run on 'all'. Specify a node." $EXIT_ARGS

    # Expand groups and flatten
    local expanded=()
    for s in "${scripts[@]}"; do
        for e in $(expand_group "$s"); do
            expanded+=("$e")
        done
    done

    local role_env=$(get_role_env "$node")

    log "Running on $node: ${expanded[*]}"

    # Ensure scripts are executable
    ssh_exec "$node" "sudo chmod +x $REMOTE_HOME/scripts/setup/*.sh 2>/dev/null || true"

    for script_name in "${expanded[@]}"; do
        # Skip scripts not applicable to node
        if [[ "$node" == "proxy" ]] && [[ "$script_name" =~ ^(raid|disk|pg|repl|pgbench-init|sysbench-init)$ ]]; then
            info "Skipping $script_name (not applicable to proxy)"
            continue
        fi
        if [[ "$node" != "proxy" ]] && [[ "$script_name" == "pgcat" ]]; then
            info "Skipping pgcat (only for proxy)"
            continue
        fi

        local script_path=$(get_script_path "$script_name")
        local cmd="sudo ${role_env:+$role_env }$script_path"

        # Special handling for replication
        if [[ "$script_name" == "repl" ]]; then
            case "$node" in
                primary) cmd="sudo $script_path primary" ;;
                sync)    cmd="sudo $script_path standby sync-replica" ;;
                async)   cmd="sudo $script_path standby async-replica" ;;
            esac
        fi

        log "  → $script_name"
        ssh_exec "$node" "$cmd" || die "Failed: $script_name on $node" $EXIT_REMOTE
    done

    log "Completed on $node"
}

# =============================================================================
# COMMANDS: BENCHMARK
# =============================================================================

cmd_bench() {
    local id=${1:-}
    local mode=${2:-pgcat}

    [[ -z "$id" ]] && die "Usage: ./bs bench <id> [mode]\n  mode: pgcat|direct (default: pgcat)" $EXIT_ARGS
    [[ "$mode" != "pgcat" && "$mode" != "direct" ]] && die "Invalid mode: $mode (use: pgcat|direct)" $EXIT_ARGS

    require_infra

    local db_ip=$(get_ip primary private_ip)
    local proxy_ip=$(get_ip proxy private_ip)

    local host port
    if [[ "$mode" == "pgcat" ]]; then
        host="$proxy_ip"
        port="6432"
        log "Benchmark #$id via PgCat ($proxy_ip:6432 → $db_ip)"
    else
        host="$db_ip"
        port="5432"
        log "Benchmark #$id direct ($db_ip:5432)"
    fi

    # FIO runs on primary, pgbench/sysbench on proxy
    local runner_node
    if [[ "$id" -le 10 ]]; then
        runner_node="primary"
    else
        runner_node="proxy"
    fi

    local cmd="sudo python3 $REMOTE_HOME/scripts/bench.py $id --host $host --port $port --db-host $db_ip"

    if dry "$cmd (on $runner_node)"; then
        return 0
    fi

    ssh_exec "$runner_node" "$cmd"
}

cmd_results() {
    local node=${1:-all}
    validate_node "$node"

    local nodes
    if [[ "$node" == "all" ]]; then
        nodes="primary proxy"  # Only these have results
    else
        nodes="$node"
    fi

    log "Syncing results..."
    for n in $nodes; do
        rsync_from "$n"
    done

    log "Results in: $LOCAL_RESULTS"
    ls -lt "$LOCAL_RESULTS"/*.md 2>/dev/null | head -5 || echo "  (no results yet)"
}

cmd_scenarios() {
    local scenarios_file="$SCRIPT_DIR/scripts/scenarios.json"
    [[ ! -f "$scenarios_file" ]] && die "scenarios.json not found" $EXIT_ERROR

    echo ""
    echo "BENCHMARK SCENARIOS"
    echo "==================="
    echo ""
    echo "FIO (1-10):"
    for i in 1 2 3 4 5 6 7 8 9 10; do
        local name=$(jq -r ".scenarios[\"$i\"].name // empty" "$scenarios_file")
        [[ -n "$name" ]] && printf "  %2s: %s\n" "$i" "$name"
    done
    echo ""
    echo "pgbench (11-15):"
    for i in 11 12 13 14 15; do
        local name=$(jq -r ".scenarios[\"$i\"].name // empty" "$scenarios_file")
        [[ -n "$name" ]] && printf "  %2s: %s\n" "$i" "$name"
    done
    echo ""
    echo "sysbench (21-23):"
    for i in 21 22 23; do
        local name=$(jq -r ".scenarios[\"$i\"].name // empty" "$scenarios_file")
        [[ -n "$name" ]] && printf "  %2s: %s\n" "$i" "$name"
    done
    echo ""
}

# =============================================================================
# COMMANDS: VERIFY
# =============================================================================

cmd_verify() {
    local node=${1:-all}
    validate_node "$node"

    require_infra

    log "Verifying configuration (node: $node)..."

    # Source local configs
    local config_dir="$SCRIPT_DIR/scripts/config"
    source "$config_dir/common/network.env" 2>/dev/null || true
    source "$config_dir/common/kernel.env" 2>/dev/null || true
    source "$config_dir/db/os.env" 2>/dev/null || true
    source "$config_dir/db/disk.env" 2>/dev/null || true
    source "$config_dir/db/primary.env" 2>/dev/null || true

    local mismatch=0

    check() {
        local name=$1 local_val=$2 actual_val=$3
        local l=$(echo "$local_val" | tr -d ' ' | tr '[:upper:]' '[:lower:]')
        local a=$(echo "$actual_val" | tr -d ' ' | tr '[:upper:]' '[:lower:]')

        if [[ "$l" == "$a" ]]; then
            printf "  ${GREEN}✓${NC} %-40s %s\n" "$name" "$actual_val"
        else
            printf "  ${RED}✗${NC} %-40s %s (expected: %s)\n" "$name" "$actual_val" "$local_val"
            ((mismatch++))
        fi
    }

    # Verify primary (or specified node)
    local target_node
    [[ "$node" == "all" ]] && target_node="primary" || target_node="$node"

    if [[ "$target_node" == "primary" || "$target_node" == "sync" || "$target_node" == "async" ]]; then
        echo ""
        echo "=== $target_node: OS ==="
        local os_vals=$(ssh_exec "$target_node" "cat /proc/sys/vm/swappiness /proc/sys/vm/nr_hugepages /sys/kernel/mm/transparent_hugepage/enabled 2>/dev/null | tr '\n' '|'")
        IFS='|' read -r a_swap a_hp a_thp <<< "$os_vals"
        a_thp=$(echo "$a_thp" | grep -o '\[.*\]' | tr -d '[]')

        check "vm.swappiness" "$VM_SWAPPINESS" "$a_swap"
        check "vm.nr_hugepages" "$VM_NR_HUGEPAGES" "$a_hp"
        check "transparent_hugepage" "$THP_ENABLED" "$a_thp"

        echo ""
        echo "=== $target_node: PostgreSQL ==="
        local pg_vals=$(ssh_exec "$target_node" "sudo -u postgres psql -t -A -c \"SELECT setting FROM pg_settings WHERE name='shared_buffers'\" 2>/dev/null")
        local pg_shared=$((${pg_vals:-0} * 8 / 1024 / 1024))GB
        check "shared_buffers" "$PG_SHARED_BUFFERS" "$pg_shared"

        local sync_commit=$(ssh_exec "$target_node" "sudo -u postgres psql -t -A -c \"SHOW synchronous_commit\" 2>/dev/null")
        check "synchronous_commit" "$PG_SYNCHRONOUS_COMMIT" "$sync_commit"
    fi

    if [[ "$node" == "all" || "$node" == "proxy" ]]; then
        echo ""
        echo "=== proxy: PgCat ==="
        local pgcat_status=$(ssh_exec proxy "systemctl is-active pgcat 2>/dev/null || echo inactive")
        if [[ "$pgcat_status" == "active" ]]; then
            printf "  ${GREEN}✓${NC} %-40s %s\n" "pgcat.service" "active"
        else
            printf "  ${RED}✗${NC} %-40s %s\n" "pgcat.service" "$pgcat_status"
            ((mismatch++))
        fi
    fi

    if [[ "$node" == "all" ]]; then
        echo ""
        echo "=== Replication ==="
        local repl_status=$(ssh_exec primary "sudo -u postgres psql -t -A -c \"SELECT client_addr || '|' || state || '|' || sync_state FROM pg_stat_replication ORDER BY client_addr\" 2>/dev/null")
        if [[ -n "$repl_status" ]]; then
            echo "$repl_status" | while IFS='|' read -r addr state sync; do
                local name="unknown"
                [[ "$addr" == "10.0.1.11" ]] && name="sync"
                [[ "$addr" == "10.0.1.12" ]] && name="async"
                printf "  ${GREEN}✓${NC} %-40s %s (%s)\n" "$name ($addr)" "$state" "$sync"
            done
        else
            printf "  ${YELLOW}!${NC} No replicas connected\n"
        fi
    fi

    echo ""
    if [[ $mismatch -eq 0 ]]; then
        log "All checks passed"
    else
        warn "$mismatch mismatch(es) found"
    fi

    return $mismatch
}

# =============================================================================
# COMMANDS: UTILITY
# =============================================================================

cmd_status() {
    echo ""
    echo "=== STATUS ==="

    if [[ ! -f "$INFRA_JSON" ]]; then
        warn "No infrastructure (infra.json missing)"
        return 0
    fi

    echo ""
    echo "Topology: $(jq -r '.topology.value // "proxy-primary"' "$INFRA_JSON")"
    echo ""
    printf "  %-12s %-16s %-15s\n" "NODE" "PUBLIC IP" "PRIVATE IP"
    printf "  %-12s %-16s %-15s\n" "----" "---------" "----------"

    for node in $(all_nodes); do
        local pub=$(get_ip "$node" public_ip 2>/dev/null || echo "N/A")
        local priv=$(get_ip "$node" private_ip 2>/dev/null || echo "N/A")
        printf "  %-12s %-16s %-15s\n" "$node" "$pub" "$priv"
    done

    echo ""
    local vcpu=$(jq -r '.db_nodes.value.primary.vcpu // "?"' "$INFRA_JSON")
    local ram=$(jq -r '.db_nodes.value.primary.ram_gb // "?"' "$INFRA_JSON")
    echo "DB Specs: ${vcpu} vCPU, ${ram}GB RAM"
    echo ""
}

cmd_warm() {
    local target=${1:-all}

    log "Warming cache: $target"

    ssh_exec primary "sudo -u postgres psql -c 'CREATE EXTENSION IF NOT EXISTS pg_prewarm;'" || true

    if [[ "$target" == "all" || "$target" == "pgbench" ]]; then
        log "  → pgbench tables"
        if dry "pg_prewarm pgbench_accounts"; then
            :
        else
            ssh_exec primary "sudo -u postgres psql -d bench -c \"SELECT pg_prewarm('pgbench_accounts');\"" 2>/dev/null || warn "pgbench tables not found"
        fi
    fi

    if [[ "$target" == "all" || "$target" == "sysbench" ]]; then
        log "  → sysbench tables"
        if dry "pg_prewarm sysbench tables"; then
            :
        else
            ssh_exec primary "sudo -u postgres psql -d sysbench -c \"SELECT pg_prewarm(c.oid) FROM pg_class c JOIN pg_namespace n ON n.oid=c.relnamespace WHERE n.nspname='public' AND c.relkind='r';\"" 2>/dev/null || warn "sysbench tables not found"
        fi
    fi

    log "Cache warming complete"
}

cmd_cleanup() {
    log "Killing remote processes..."

    for node in $(all_nodes); do
        if dry "pkill bench.py/pgbench/fio on $node"; then
            continue
        fi
        ssh_exec "$node" "sudo pkill -f 'bench.py|pgbench|fio|sysbench' 2>/dev/null || true"
    done

    log "Cleanup complete"
}

# =============================================================================
# COMMANDS: AMI
# =============================================================================

cmd_bake() {
    local target=${1:-all}
    local version=${2:-$(date +%Y%m%d)}

    require_infra

    log "Baking AMI (target: $target, version: $version)"

    local profile="boxloop-admin"
    local region="ap-southeast-1"

    bake_one() {
        local node=$1 name=$2
        local instance_id=$(jq -r ".db_nodes.value.${node}.instance_id // .proxy_node.value.instance_id" "$INFRA_JSON")

        if dry "aws ec2 create-image --instance-id $instance_id --name $name"; then
            return 0
        fi

        log "  Creating: $name from $instance_id"
        aws ec2 create-image --profile "$profile" --region "$region" \
            --instance-id "$instance_id" --name "$name" --no-reboot \
            --query 'ImageId' --output text
    }

    [[ "$target" == "all" || "$target" == "db" ]] && bake_one "primary" "postgres-golden-$version"
    [[ "$target" == "all" || "$target" == "proxy" ]] && bake_one "proxy" "proxy-golden-$version"

    log "AMI creation initiated (check with: ./bs ami-list)"
}

cmd_ami_list() {
    local profile="boxloop-admin"
    local region="ap-southeast-1"

    log "Golden AMIs:"
    aws ec2 describe-images --profile "$profile" --region "$region" \
        --owners self --filters "Name=name,Values=*golden*" \
        --query 'Images[*].[ImageId,Name,State,CreationDate]' --output table
}

cmd_ami_delete() {
    local ami_id=${1:-}
    [[ -z "$ami_id" ]] && die "Usage: ./bs ami-delete <ami-id>" $EXIT_ARGS

    local profile="boxloop-admin"
    local region="ap-southeast-1"

    if dry "aws ec2 deregister-image --image-id $ami_id"; then
        return 0
    fi

    log "Deleting AMI: $ami_id"
    aws ec2 deregister-image --profile "$profile" --region "$region" --image-id "$ami_id"
    log "Done"
}

# =============================================================================
# HELP
# =============================================================================

cmd_help() {
    cat << 'EOF'

bs - Benchmark Script (Atomic, Composable)

USAGE
  ./bs <command> [args] [-n] [-v] [--no-color]

GLOBAL FLAGS
  -n, --dry-run    Show commands without executing
  -v, --verbose    Show command details
  --no-color       Disable color output

INFRASTRUCTURE
  tf apply         Terraform apply + generate infra.json
  tf destroy       Terraform destroy + remove infra.json
  tf output        Regenerate infra.json from existing infra

CONNECTIVITY
  test             Validate infra.json + SSH connectivity
  wait [node]      Wait for SSH ready (default: all)
  sync [node]      Rsync scripts to node (default: all)
  ssh <node>       Interactive SSH session

EXECUTE
  run <node> <scripts...>
    node:    primary | sync | async | proxy
    scripts: deps os raid disk pg repl pgcat pgbench-init sysbench-init
    groups:  config (deps+os+raid+disk+pg)
             replica (config+repl)
             all (replica+inits)

BENCHMARK
  bench <id> [mode]   Run scenario (mode: pgcat|direct, default: pgcat)
  results [node]      Sync results from node (default: primary+proxy)
  scenarios           List all benchmark scenarios

VERIFY & UTILITY
  verify [node]       Check config matches local (default: all)
  status              Show infrastructure status
  warm [target]       Warm cache (target: all|pgbench|sysbench)
  cleanup             Kill remote benchmark processes

AMI
  bake [target] [ver] Bake AMI (target: all|db|proxy)
  ami-list            List golden AMIs
  ami-delete <id>     Delete AMI

EXIT CODES
  0  Success
  1  General error
  2  Invalid arguments
  3  SSH connection failed
  4  Remote script failed
  5  Missing infra.json

EXAMPLES

  # Provision infrastructure only
  ./bs tf apply && ./bs wait && ./bs sync

  # Setup with config only (no data init)
  ./bs run primary config repl
  ./bs run sync replica &
  ./bs run async replica &
  wait
  ./bs run proxy deps os pgcat
  ./bs verify

  # Add data init later
  ./bs run primary pgbench-init sysbench-init

  # Run benchmarks
  ./bs bench 11 && ./bs bench 12 && ./bs results
  for i in {1..10}; do ./bs bench $i; done && ./bs results

  # Debug with dry-run
  ./bs run primary config -n
  ./bs bench 11 -n

  # Fix single component
  ./bs sync primary && ./bs run primary pg -v

EOF
}

# =============================================================================
# MAIN
# =============================================================================

main() {
    # Parse global flags first (sets REMAINING_ARGS)
    parse_flags "$@"
    set -- "${REMAINING_ARGS[@]}"

    local cmd=${1:-help}
    shift || true

    case "$cmd" in
        tf)         cmd_tf "$@" ;;
        test)       cmd_test ;;
        wait)       cmd_wait "$@" ;;
        sync)       cmd_sync "$@" ;;
        ssh)        cmd_ssh "$@" ;;
        run)        cmd_run "$@" ;;
        bench)      cmd_bench "$@" ;;
        results)    cmd_results "$@" ;;
        scenarios)  cmd_scenarios ;;
        verify)     cmd_verify "$@" ;;
        status)     cmd_status ;;
        warm)       cmd_warm "$@" ;;
        cleanup)    cmd_cleanup ;;
        bake)       cmd_bake "$@" ;;
        ami-list)   cmd_ami_list ;;
        ami-delete) cmd_ami_delete "$@" ;;
        help|--help|-h) cmd_help ;;
        *)          die "Unknown command: $cmd\nRun './bs help' for usage." $EXIT_ARGS ;;
    esac
}

main "$@"
